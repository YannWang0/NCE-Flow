#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NCE-Flow å­—å¹•ç¿»è¯‘çº æ­£è„šæœ¬
ä½¿ç”¨ SiliconFlow GLM-4.6 æ¨¡å‹æ™ºèƒ½çº æ­£ .lrc å­—å¹•æ–‡ä»¶ä¸­çš„ä¸­æ–‡ç¿»è¯‘
ä¸¥æ ¼ä¿æŒåŸæœ‰æ ¼å¼ï¼Œç¡®ä¿ NCE-Flow ç¨‹åºèƒ½æ­£å¸¸è§£æ
"""

import os
import re
import time
import json
import getpass
from pathlib import Path
from typing import List, Dict, Tuple
import requests
from datetime import datetime


class TranslationFixer:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.siliconflow.cn/v1/chat/completions"
        self.model = "zai-org/GLM-4.6"

        # é€Ÿç‡é™åˆ¶ï¼šRPM 10000, TPM 400000
        self.max_rpm = 10000
        self.max_tpm = 400000
        self.request_count = 0
        self.token_count = 0
        self.start_time = time.time()

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_files = 0
        self.processed_files = 0
        self.modified_files = 0
        self.error_files = []

    def rate_limit_check(self, estimated_tokens: int = 2000):
        """æ£€æŸ¥å¹¶æ§åˆ¶è¯·æ±‚é¢‘ç‡"""
        current_time = time.time()
        elapsed = current_time - self.start_time

        # å¦‚æœè¶…è¿‡1åˆ†é’Ÿï¼Œé‡ç½®è®¡æ•°å™¨
        if elapsed >= 60:
            self.request_count = 0
            self.token_count = 0
            self.start_time = current_time
            return

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç­‰å¾…
        if self.request_count >= self.max_rpm - 10 or self.token_count + estimated_tokens >= self.max_tpm:
            wait_time = 60 - elapsed + 1
            print(f"  â³ æ¥è¿‘é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time:.1f} ç§’...")
            time.sleep(wait_time)
            self.request_count = 0
            self.token_count = 0
            self.start_time = time.time()

    def parse_lrc_file(self, file_path: str) -> Tuple[List[str], List[Dict]]:
        """
        è§£æ LRC æ–‡ä»¶ï¼Œåˆ†ç¦»å…ƒæ•°æ®å’Œå­—å¹•å†…å®¹
        è¿”å›ï¼š(å…ƒæ•°æ®è¡Œåˆ—è¡¨, å­—å¹•æ•°æ®åˆ—è¡¨)
        """
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        metadata = []
        subtitles = []

        # LRC æ—¶é—´è½´æ ¼å¼ï¼š[mm:ss.xx]
        time_pattern = re.compile(r'^\[(\d{2}:\d{2}\.\d{2})\](.+)$')

        for line in lines:
            line = line.rstrip('\n')  # ä¿ç•™å¯èƒ½çš„ç©ºè¡Œ

            # å…ƒæ•°æ®è¡Œï¼š[al:], [ar:], [ti:], [by:]
            if line.startswith('[') and any(tag in line for tag in ['[al:', '[ar:', '[ti:', '[by:']):
                metadata.append(line)
            # å­—å¹•è¡Œï¼š[æ—¶é—´]å†…å®¹
            elif time_pattern.match(line):
                match = time_pattern.match(line)
                timestamp = match.group(1)
                content = match.group(2)

                # æ£€æŸ¥æ˜¯å¦æœ‰åŒè¯­å†…å®¹ï¼ˆè‹±æ–‡|ä¸­æ–‡ï¼‰
                if '|' in content:
                    parts = content.split('|', 1)
                    english = parts[0]
                    chinese = parts[1] if len(parts) > 1 else ''
                    subtitles.append({
                        'timestamp': timestamp,
                        'english': english,
                        'chinese': chinese,
                        'has_translation': True,
                        'original_line': line
                    })
                else:
                    # æ²¡æœ‰ç¿»è¯‘çš„è¡Œï¼Œä¿æŒåŸæ ·
                    subtitles.append({
                        'timestamp': timestamp,
                        'content': content,
                        'has_translation': False,
                        'original_line': line
                    })
            # ç©ºè¡Œæˆ–å…¶ä»–è¡Œ
            else:
                if line:  # éç©ºè¡Œä½œä¸ºå…ƒæ•°æ®
                    metadata.append(line)
                else:  # ç©ºè¡Œ
                    subtitles.append({'empty': True, 'original_line': ''})

        return metadata, subtitles

    def check_and_fix_translations(self, subtitles: List[Dict], lesson_title: str) -> Tuple[List[Dict], bool]:
        """
        ä½¿ç”¨ AI æ£€æŸ¥å¹¶çº æ­£ç¿»è¯‘
        è¿”å›ï¼š(ä¿®æ­£åçš„å­—å¹•åˆ—è¡¨, æ˜¯å¦æœ‰ä¿®æ”¹)
        """
        # æå–éœ€è¦æ£€æŸ¥çš„åŒè¯­å¥å­
        bilingual_pairs = []
        for idx, sub in enumerate(subtitles):
            if sub.get('has_translation', False):
                bilingual_pairs.append({
                    'index': idx,
                    'english': sub['english'],
                    'chinese': sub['chinese']
                })

        if not bilingual_pairs:
            print(f"  â„¹ï¸  æ— åŒè¯­å†…å®¹ï¼Œè·³è¿‡")
            return subtitles, False

        print(f"  ğŸ“Š æ‰¾åˆ° {len(bilingual_pairs)} æ¡åŒè¯­å­—å¹•")

        # æ„å»º AI æç¤º
        print(f"  ğŸ”¨ æ„å»º AI æç¤º...")
        prompt = self._build_prompt(bilingual_pairs, lesson_title)
        estimated_tokens = len(prompt) + 2000
        print(f"  ğŸ“ é¢„ä¼° token æ•°: {estimated_tokens}")

        # è°ƒç”¨ API
        try:
            print(f"  ğŸ” æ£€æŸ¥é€Ÿç‡é™åˆ¶...")
            self.rate_limit_check(estimated_tokens=estimated_tokens)

            print(f"  ğŸš€ å‘é€ API è¯·æ±‚åˆ° {self.model}...")
            start_time = time.time()

            response = requests.post(
                self.base_url,
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä½ç²¾é€šè‹±è¯­æ•™å­¦çš„ä¸“ä¸šç¿»è¯‘ï¼Œæ“…é•¿ä¸ºä¸­å›½å­¦ç”Ÿæä¾›å‡†ç¡®ã€è‡ªç„¶çš„æ–°æ¦‚å¿µè‹±è¯­æ•™æç¿»è¯‘ã€‚"
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "temperature": 0.3,
                    "max_tokens": 4000
                },
                timeout=30
            )

            elapsed = time.time() - start_time
            print(f"  âœ… API å“åº”æˆåŠŸ (è€—æ—¶ {elapsed:.2f}s)")

            self.request_count += 1

            if response.status_code != 200:
                print(f"  âŒ API è¯·æ±‚å¤±è´¥ï¼š{response.status_code} - {response.text}")
                return subtitles, False

            result = response.json()
            tokens_used = result.get('usage', {}).get('total_tokens', 0)
            self.token_count += tokens_used
            print(f"  ğŸ“Š ä½¿ç”¨ token: {tokens_used} (ç´¯è®¡: {self.token_count})")

            # è§£æ AI è¿”å›çš„ç»“æœ
            print(f"  ğŸ” è§£æ AI å“åº”...")
            ai_response = result['choices'][0]['message']['content']
            corrections = self._parse_ai_response(ai_response)

            if not corrections:
                print(f"  âœ“  AI è®¤ä¸ºç¿»è¯‘å‡†ç¡®ï¼Œæ— éœ€ä¿®æ”¹")
                return subtitles, False

            print(f"  ğŸ“ å‘ç° {len(corrections)} å¤„éœ€è¦ä¿®æ­£")

            # åº”ç”¨ä¿®æ­£
            modified = False
            for correction in corrections:
                idx = correction['index']
                new_chinese = correction['corrected_chinese']
                reason = correction.get('reason', 'æ— è¯´æ˜')

                if subtitles[idx]['chinese'] != new_chinese:
                    print(f"\n    âœï¸  ä¿®æ­£ #{idx + 1} [{subtitles[idx]['timestamp']}]:")
                    print(f"       è‹±æ–‡: {subtitles[idx]['english']}")
                    print(f"       åŸè¯‘: {subtitles[idx]['chinese']}")
                    print(f"       æ–°è¯‘: {new_chinese}")
                    print(f"       ç†ç”±: {reason}")
                    subtitles[idx]['chinese'] = new_chinese
                    modified = True

            return subtitles, modified

        except requests.Timeout:
            print(f"  âŒ API è¯·æ±‚è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
            return subtitles, False
        except requests.RequestException as e:
            print(f"  âŒ ç½‘ç»œé”™è¯¯: {str(e)}")
            return subtitles, False
        except Exception as e:
            print(f"  âŒ å¤„ç†å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return subtitles, False

    def _build_prompt(self, bilingual_pairs: List[Dict], lesson_title: str) -> str:
        """æ„å»ºå‘é€ç»™ AI çš„æç¤º"""
        pairs_text = ""
        for i, pair in enumerate(bilingual_pairs):
            pairs_text += f"{i}. è‹±æ–‡: {pair['english']}\n   ä¸­æ–‡: {pair['chinese']}\n\n"

        prompt = f"""è¯·ä»”ç»†æ£€æŸ¥ä»¥ä¸‹æ–°æ¦‚å¿µè‹±è¯­è¯¾æ–‡ã€Š{lesson_title}ã€‹çš„åŒè¯­å­—å¹•ç¿»è¯‘ï¼Œçº æ­£å…¶ä¸­ç”Ÿç¡¬ã€ä¸å‡†ç¡®æˆ–ä¸è‡ªç„¶çš„ä¸­æ–‡ç¿»è¯‘ã€‚

**é‡è¦è¯´æ˜ï¼š**
1. è¿™æ˜¯æ–°æ¦‚å¿µè‹±è¯­æ•™æï¼Œæ¯å¥è¯éƒ½æœ‰ç‰¹å®šçš„æ•™å­¦ç›®çš„å’Œåœºæ™¯
2. **ç¿»è¯‘åŸåˆ™**ï¼š
   - è¦å‚è€ƒä¸Šä¸‹æ–‡ç†è§£è¯­å¢ƒï¼Œä½†ä¸»è¦å…³æ³¨æ¯å¥è¯æœ¬èº«çš„å‡†ç¡®æ€§
   - ä¸è¦å› ä¸ºä¸Šä¸‹æ–‡è€Œæ”¹å˜å•å¥çš„æ•™å­¦æ„å›¾
   - æ¯å¥è¯éƒ½æ˜¯ç‹¬ç«‹çš„æ•™å­¦å•å…ƒï¼Œè¦ç¡®ä¿å•å¥ç¿»è¯‘çš„å‡†ç¡®æ€§å’Œæ•™å­¦ä»·å€¼
3. **é¿å…ç›´è¯‘é”™è¯¯**ï¼š
   - ä¹ è¯­å’Œå›ºå®šè¡¨è¾¾è¦ç”¨åœ°é“çš„ä¸­æ–‡ï¼ˆå¦‚ "How do you do?" â†’ "ä½ å¥½"ï¼Œè€Œé"ä½ æ˜¯æ€ä¹ˆåšåˆ°çš„"ï¼‰
   - "Pardon?" â†’ "ä»€ä¹ˆï¼Ÿè¯·å†è¯´ä¸€é"ï¼Œè€Œé"åŸè°…ï¼Ÿ"
   - "Good for you!" â†’ "ä½ çœŸæ£’ï¼"ï¼Œè€Œé"å¯¹ä½ æœ‰å¥½å¤„"
4. **ç¬¦åˆä¸­å›½å­¦ç”Ÿä¹ æƒ¯**ï¼š
   - ç¿»è¯‘è¦è‡ªç„¶ã€å£è¯­åŒ–
   - é€‚åˆåˆå­¦è€…ç†è§£
   - ä¿æŒæ•™å­¦åœºæ™¯çš„çœŸå®æ„Ÿ
5. åªçº æ­£æ˜æ˜¾é”™è¯¯çš„ç¿»è¯‘ï¼Œå‡†ç¡®çš„ç¿»è¯‘è¯·ä¿æŒä¸å˜

**å­—å¹•å†…å®¹ï¼š**
{pairs_text}

**è¯·ä»¥JSONæ ¼å¼è¿”å›éœ€è¦ä¿®æ­£çš„ç¿»è¯‘ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š**
```json
[
  {{"index": 0, "corrected_chinese": "ä¿®æ­£åçš„ä¸­æ–‡ç¿»è¯‘", "reason": "ä¿®æ­£ç†ç”±"}},
  {{"index": 2, "corrected_chinese": "ä¿®æ­£åçš„ä¸­æ–‡ç¿»è¯‘", "reason": "ä¿®æ­£ç†ç”±"}}
]
```

å¦‚æœæŸå¥ç¿»è¯‘å‡†ç¡®æ— éœ€ä¿®æ”¹ï¼Œåˆ™ä¸è¦åœ¨è¿”å›ç»“æœä¸­åŒ…å«å®ƒã€‚åªè¿”å›éœ€è¦ä¿®æ­£çš„å¥å­ã€‚
"""
        return prompt

    def _parse_ai_response(self, response: str) -> List[Dict]:
        """è§£æ AI è¿”å›çš„ JSON ç»“æœ"""
        try:
            # æå– JSON éƒ¨åˆ†ï¼ˆå¯èƒ½è¢« ```json ``` åŒ…è£¹ï¼‰
            json_match = re.search(r'```json\s*(\[.*?\])\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # å°è¯•ç›´æ¥æŸ¥æ‰¾ JSON æ•°ç»„
                json_match = re.search(r'(\[.*?\])', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    return []

            corrections = json.loads(json_str)
            return corrections if isinstance(corrections, list) else []
        except Exception as e:
            print(f"  âš ï¸  è§£æ AI å“åº”å¤±è´¥: {str(e)}")
            return []

    def reconstruct_lrc_file(self, metadata: List[str], subtitles: List[Dict]) -> str:
        """é‡æ–°ç»„è£… LRC æ–‡ä»¶å†…å®¹ï¼Œä¸¥æ ¼ä¿æŒåŸæ ¼å¼"""
        lines = []

        # æ·»åŠ å…ƒæ•°æ®
        for meta in metadata:
            lines.append(meta)

        # æ·»åŠ å­—å¹•
        for sub in subtitles:
            if sub.get('empty', False):
                lines.append('')
            elif sub.get('has_translation', False):
                # é‡å»ºåŒè¯­å­—å¹•è¡Œ
                line = f"[{sub['timestamp']}]{sub['english']}|{sub['chinese']}"
                lines.append(line)
            else:
                # ä¿æŒåŸæ ·
                lines.append(sub['original_line'])

        return '\n'.join(lines) + '\n'

    def process_file(self, file_path: str):
        """å¤„ç†å•ä¸ª LRC æ–‡ä»¶"""
        try:
            file_name = os.path.basename(file_path)
            print(f"\n{'='*60}")
            print(f"ğŸ“„ [{self.processed_files + 1}/{self.total_files}] {file_name}")
            print(f"{'='*60}")

            # è§£ææ–‡ä»¶
            print(f"  ğŸ“– è¯»å–å¹¶è§£ææ–‡ä»¶...")
            metadata, subtitles = self.parse_lrc_file(file_path)
            print(f"  âœ“  å…ƒæ•°æ®: {len(metadata)} è¡Œ")
            print(f"  âœ“  å­—å¹•å†…å®¹: {len(subtitles)} è¡Œ")

            # æå–è¯¾ç¨‹æ ‡é¢˜
            lesson_title = file_name.replace('.lrc', '')

            # æ£€æŸ¥å¹¶ä¿®æ­£ç¿»è¯‘
            corrected_subtitles, modified = self.check_and_fix_translations(subtitles, lesson_title)

            # å¦‚æœæœ‰ä¿®æ”¹ï¼Œä¿å­˜æ–‡ä»¶
            if modified:
                print(f"\n  ğŸ’¾ ä¿å­˜ä¿®æ”¹...")
                # å¤‡ä»½åŸæ–‡ä»¶
                backup_path = file_path + '.backup'
                os.rename(file_path, backup_path)
                print(f"  âœ“  å·²åˆ›å»ºå¤‡ä»½")

                # å†™å…¥ä¿®æ­£åçš„å†…å®¹
                new_content = self.reconstruct_lrc_file(metadata, corrected_subtitles)
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                print(f"  âœ“  å·²å†™å…¥æ–°å†…å®¹")

                # åˆ é™¤å¤‡ä»½
                os.remove(backup_path)
                print(f"  âœ“  å·²åˆ é™¤å¤‡ä»½")

                self.modified_files += 1
                print(f"\n  âœ… æ–‡ä»¶å·²æ›´æ–°")
            else:
                print(f"\n  âœ… ç¿»è¯‘å‡†ç¡®ï¼Œæ— éœ€ä¿®æ”¹")

            self.processed_files += 1

        except Exception as e:
            print(f"\n  âŒ å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            self.error_files.append(file_path)
            self.processed_files += 1

    def process_all_files(self):
        """å¤„ç†æ‰€æœ‰ NCE æ–‡ä»¶å¤¹ä¸­çš„ LRC æ–‡ä»¶"""
        folders = ['NCE1', 'NCE2', 'NCE3', 'NCE4']
        all_files = []

        # æ”¶é›†æ‰€æœ‰ LRC æ–‡ä»¶
        print(f"\nğŸ” æ‰«ææ–‡ä»¶å¤¹...")
        for folder in folders:
            folder_path = Path(folder)
            if folder_path.exists():
                lrc_files = list(folder_path.glob('*.lrc'))
                print(f"  {folder}: {len(lrc_files)} ä¸ªæ–‡ä»¶")
                all_files.extend([str(f) for f in lrc_files])
            else:
                print(f"  âš ï¸  {folder} ä¸å­˜åœ¨")

        self.total_files = len(all_files)
        print(f"\nğŸ¯ å…±æ‰¾åˆ° {self.total_files} ä¸ª LRC æ–‡ä»¶")
        print(f"â±ï¸  å¼€å§‹å¤„ç†...")

        # é€ä¸ªå¤„ç†
        for file_path in all_files:
            self.process_file(file_path)

        # æ˜¾ç¤ºæ€»ç»“
        print(f"\n{'='*60}")
        print(f"âœ¨ å¤„ç†å®Œæˆï¼")
        print(f"{'='*60}")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»æ–‡ä»¶æ•°: {self.total_files}")
        print(f"   å·²å¤„ç†: {self.processed_files}")
        print(f"   å·²ä¿®æ”¹: {self.modified_files}")
        print(f"   å¤±è´¥: {len(self.error_files)}")
        print(f"   æˆåŠŸç‡: {(self.processed_files - len(self.error_files)) / self.total_files * 100:.1f}%")
        print(f"\nâš¡ API ä½¿ç”¨:")
        print(f"   æ€»è¯·æ±‚æ•°: {self.request_count}")
        print(f"   æ€» Token: {self.token_count}")

        if self.error_files:
            print(f"\nâŒ ä»¥ä¸‹æ–‡ä»¶å¤„ç†å¤±è´¥ï¼š")
            for f in self.error_files:
                print(f"   - {os.path.basename(f)}")


def main():
    print("="*60)
    print("  NCE-Flow å­—å¹•ç¿»è¯‘çº æ­£å·¥å…·")
    print("  ä½¿ç”¨ SiliconFlow GLM-4.6 æ™ºèƒ½çº æ­£ç¿»è¯‘")
    print("="*60)

    # è·å– API Key
    api_key = getpass.getpass("\nè¯·è¾“å…¥ä½ çš„ SiliconFlow API Key: ")

    if not api_key:
        print("âŒ API Key ä¸èƒ½ä¸ºç©ºï¼")
        return

    # ç¡®è®¤å¼€å§‹
    print("\nâš ï¸  å³å°†å¼€å§‹å¤„ç†æ‰€æœ‰ LRC æ–‡ä»¶ï¼ŒåŸæ–‡ä»¶ä¼šè¢«ä¿®æ”¹ï¼ˆå¤„ç†å‰ä¼šè‡ªåŠ¨å¤‡ä»½ï¼‰")
    confirm = input("ç¡®è®¤å¼€å§‹ï¼Ÿ(yes/no): ")

    if confirm.lower() not in ['yes', 'y']:
        print("âŒ å·²å–æ¶ˆ")
        return

    # å¼€å§‹å¤„ç†
    fixer = TranslationFixer(api_key)
    start_time = datetime.now()

    fixer.process_all_files()

    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    print(f"\nâ±ï¸  æ€»è€—æ—¶: {duration:.1f} ç§’")


if __name__ == "__main__":
    main()
